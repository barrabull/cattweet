\section{Arquitectura de la solución}
	\input{texs/arquitectura_plataforma.tex}
	
	\input{texs/diagrama_software.tex}
	
\section{Plataformas y herramientas utilizadas}

\input{texs/plataformas_herramientas.tex}

\section{Implementación del prototipo}
\input{texs/caracteristicas-computador.tex}

\input{texs/modelo-datos.tex}

\subsection{Análisis de la línea editorial del medio objetivo}
	\input{texs/analisis-linea-editorial.tex}
\newpage

\subsection{Geolocalización de usuarios}\label{sec:geo}
\label{subsec:geo1}
	\input{texs/implementacion-geo-usuarios.tex}

\newpage
\subsection{Captación de usuarios}

El proceso de captación del conjunto de usuarios esta diseñado con la intención de obtener todas y todos los usuarios residentes en territorio Chileno dado que dicho catastro no existe en ninguna fuente oficial actualizada. El procedimiento se basa en las siguientes dos consideraciones: c
\begin{enumerate}
	\item Los generadores de información poseen una gran base de seguidores \cite{JavaEtAl:07}.
	\item Es habitual que los seguidores de medios de prensa al querer difundir una información le escriban un tweet a algún medio de prensa o figura de autoridad, esperando que este realice un re-tweet, para llegar también a su base de seguidores.
\end{enumerate}

El proceso de construcción de la lista de usuarios se componen de dos grandes etapas, las cuales son explicadas a continuación:

\input{texs/etapas-captacion-usuarios.tex}

\subsubsection{Captura de los medios de prensa (MP)}

Para generar la lista de medios de prensa (MP) se accede a los medios de prensa registrados en las tres asociaciones más grandes de medios de comunicación de Chile:
\begin{itemize}
	\item \textit{ANP (Asociación Nacional de Prensa)} \cite{anpWebsite}: Asociación gremial constituida el 24 de agosto de 1951. Agrupa a los principales diarios y revistas del país.
	\item \textit{ANARCICH (Asociación nacional de Radios Comunitarias y Ciudadanas de Chile)} \cite{anarcichWebsite}: Es el organismo que agrupa a 300 radios comunitarias y ciudadanas de todo el país. 
	\item \textit{ARCHI (Asociación de Radiodifusores de Chile)} \cite{archiWebsite}: Fundada en 1933 es la organización gremial de medios de comunicación social más antigua de Chile.
\end{itemize}	

Ninguna de las asociaciones de medios de prensa considerados anteriormente (ANP, ANARCICH y ARCHI) cuentan con directorios públicos \cite{mediosArchi} \cite{mediosaAnp} \cite{mediosAnarcich} que provean las cuentas oficiales de twitter de los diversos medios. Por lo cual, para recolectar las cuentas de twitter de éstos, se implementa el siguiente algoritmo ejecutado por un ser humano:

\begin{algorithm}[H]
	\caption{Construcción lista de medios}\label{mediosPrensa}
	\begin{algorithmic}[1]
		\Function{getTwitterAccount}{listaMedios}
		\For{medio in listaMedios}
		\State busqueda $\gets$ 'site:twitter.com'+medio.nombre+medio.tipo +'chile'
		\State resultGoogle $\gets$ BusquedaGoogle ( busqueda, $limit=12$)
		\For{result in resultGoogle}
		\If{result.title \&\& result.description se relacionan con medio  }
		\State medio.screenName $\gets$ result.screenName
		\EndIf 
		\EndFor
		\EndFor
		\State return listaMedios
		\EndFunction	
		%	\Function{getUsersFromBd}{comuna}
		%		\State sql = 'SELECT usuario WHERE usuario.ubicacion LIKE "\%" + comuna;
		%		\State return execute(sql);
		%	\EndFunction	
	\end{algorithmic}
\end{algorithm}

Tras aplicar este algoritmo, los resultados obtenidos fueron los siguientes:

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		Asociación & Nº asoc. con cuentas & Nº asoc. totales \\ \hline
		ANP & 43 & 93 \\ \hline
		ANARCICH & 23 & 99 \\ \hline
		ARCHI & 9 & 304 \\ \hline
	\end{tabular}
	\caption {Cantidad de miembros de las distintas asociaciones de prensa en Chile con cuentas en Twitter al 5 de junio del 2014.}
\end{table}


\subsubsection{Captura followers de los medios de prensa (FMP)}

Tras obtener la lista de medios de prensa, mediante la API de Twitter se recopilan los seguidores de cada uno de los medios de prensa. El algoritmo continuación realiza esta tarea requiere de realizar pero debe incluir intervalos de pausas para respetar las restricciones de número de solicitudes por hora que impone la API.

\begin{algorithm}[H]
	\caption{Captura de usuarios}\label{capturaUsuarios}
	\begin{algorithmic}[1]
		\Function{GetPop}{mediosPrensa}
		\For{medio in mediosPrensa} 
		\If{GetFriendsInformation(medio, api)}
		\State Sleep(2);
		\Else
		\State Sleep(60*15);
		\State GetFriendsInformation(medio, api)
		\EndIf
		\EndFor
		\EndFunction
		
		\Function{GetFriendsInformation}{user, api}	
		\State TwitterFriends $gets$ api.GetFollowers(screenName=user)
		\If {TwitterFriends.length > 0}
		\For {Friends in TwitterFriends}:
		\State SaveInBd(Friends)
		\EndFor
		\Else
		\State Sleep(60*15);
		\EndIf
		\EndFunction
		
	\end{algorithmic}
\end{algorithm}

Una de las dificultades presentadas en el algoritmo anterior, era que ante usuarios con más de 1,5 millones de seguidores la petición a la API se demoraba un tiempo excesivo (más de 48 horas) y retornaba error por \emph{timeout} de la conexión. Para sortear esta dificultad fue necesario modificar la API Python Twitter directamente, agregando el retorno del cursor aún cuando se agota la conexión con la API y guardando los resultados parciales de las respuestas. El cursor de una llamada en la API es similar a un índice que permite realizar solicitudes de manera segmentada a la API \footnote{ Al día 26/10/2015 no se encontraba disponible la mejora en el \emph{Github} oficial de la librería \cite{pythonTwitterGithub} }. Esta modificación fue realizada en base a las recomendaciones y comentarios disponibles en los grupos de desarrolladores de la librería \cite{pythonTwitterCode} \cite{pythonTwitterGithub}. 

\input{texs/alg-modificacion-api-twitter.tex}

El algoritmo se demora en promedio 2,6945531 segundos en descargar los datos de un usuario y almacenarlos en el sistema.

\subsection{Captura de tweets}

El proceso de captura de tweets se realiza obteniendo los 100 últimos tweets de cada uno de los usuarios y usuarias recolectadas en la fase anterior, sin discriminación ni priorización alguna, tal como muestra el siguiente algoritmo:

\begin{algorithm}[H]
	\caption{Algoritmo para la captura de tweets.}\label{getTweets}
	\begin{algorithmic}[1]
		\Function{GetTweets}{}
		\State usuarios $\gets$ getUsersFromBD();
		\For {usuario in usuarios}
		\State GetUserTimeline(id\_user=usuario.id);
		\EndFor
		\State time.sleep(5);
		\EndFunction
		
		\Function{GetUserTimeline}{id\_user}:
		\State statuses $\gets$ api.GetUserTimeline(user\_id=id\_user,count=100);
		\State SaveTweetInBD(statuses);
		
		\If {statuses.error == 34}
		\Comment{La cuenta ya no existe}
		\State return 1;
		\EndIf
		
		\If {statuses.error == 179}
		\Comment{La cuenta es privada}
		\State return 1;
		\EndIf
		
		\If {statuses.error == 88}
		\Comment{Limite de solicitudes excedidas}
		\State time.sleep(5*60);
		\State return
		\EndIf
		\EndFunction
	\end{algorithmic}
\end{algorithm}

El algoritmo planteado principalmente en su primera etapa realiza una búsqueda de los usuarios y sus respectivos estados referentes a si han sido recolectados sus últimos tweets (en cuyo caso se van a buscar los 100 tweets más recientes a partir del último recogido) o no (en cuyo caso se van a buscar los 100 tweets más recientes), posteriormente se almacenan en la base de datos los tweets recibidos. Es importante resaltar que este algoritmo gestiona las distintas pausas necesarias para respetar los límites de la API Twitter y posibles restricciones sobre si la cuenta no existe o es privada. 

El algoritmo se demora en promedio 0,9658139 segundos en descargar los tweets de un usuario y almacenarlos en el sistema.

\subsection{Procesamiento de los tweets}

El procesamiento de los tweets se define en tres procesos:
\begin{enumerate}
	\item{Definición del tópico.}
	\item{Obtención del conjunto de tweets relacionados al tópico.}
	\item{Depuración de conjunto de tweets relacionados al tópico.}
\end{enumerate}

\subsubsection{Definición del tópico}

Un tópico son las palabras claves que definen una búsqueda temática realizada por el administrador del sistema mediante la plataforma web, cada tópico posee los siguientes atributos:
\begin{itemize}
	\item \textit{Fecha de inicio} : Se refiere a la fecha de inicio de emisión de los tweets objetivos que se requiere reunir.
	\item \textit{Fecha última actualización}: Se refiere a la última fecha en la cual se realizó alguna modificación referente al tópico.
	\item \textit{Título}: Se refiere a las palabras claves que definen al tópico. 
	\item \textit{Comuna}: Comuna relacionada al tópico.
	\item \textit{Tasa de contenidos georeferenciados}: Relación entre tweets con relación geográfica y los tweets totales.
	\item \textit{Cantidad de tweets relacionados}: Total de tweets depurados del conjunto de tweets relacionados. 
\end{itemize}

\subsubsection{Obtención del conjunto de tweets relacionados al tópico}

Para obtener el conjunto de tweets relacionados al tópico se realiza una búsqueda en todos los tweets emitidos durante el periodo de interés
y que contengan las palabras claves que definen al tópico. Posteriormente se eliminan los tweets que poseen una similitud 0.85\% en sus textos 
utilizando la librería \emph{difflib}. Esta consulta se demora entre 30 y 130 segundos.

\begin{algorithm}[H]
	\caption{Obtención del conjunto de tweets relacionados al tópico}\label{getTweetsKeyword}
	\begin{algorithmic}[1]
		
		\Function{getTweetKeyword}{keywords,fecha}:
		%\Comment{Query tematica: va a buscar tweets que contengan una cierta keyword y retorna un array con las palabras que la contengan}
		\State tweets $\gets$ getTweetsFromBD(keywords, fecha);
		\State tweets $\gets$ eliminacionTweetsRepetidos(tweets);
		\State return tweets
		\EndFunction
	\end{algorithmic}
\end{algorithm}	



\subsubsection{Depuración de conjunto de tweets relacionados al tópico}

El proceso de depuración del conjunto de tweets obtenidos en el proceso anterior considera dos etapas distintas dependiendo del volumen de los tweets involucrados.

Un gran desafío en la depuración de los tweets, es discernir si un tweet en particular se relaciona o no con la temática del tópico, o por el contrario, si responde a una temática completamente distinta (y fue relacionado con el tópico únicamente por concordancia textual). Por ejemplo, si el tópico se refiere a "la paralización del registro civil", con la keyword 'paro' se busca excluir todos los tweets que se refieran a un "paro cardíaco" o de "la acción de levantarse".

Para aplicar un filtro efectivo se consideran las siguientes premisas:
\begin{itemize}
	\item El administrador del sistema posee poco tiempo (una tarea como eliminar filtros es un trabajo repetitivo y monótono, que requiere varias horas hombres para su desarrollo).
	\item Es fundamental filtrar con precisión los tweets que no corresponden a la temática.
\end{itemize}

Para conjuntos de tweets de menos de 300 tweets se considera que su depuración puede ser realizada de manera manual, debido a que no es un gran conjunto de datos y su análisis manual no demanda tiempo excesivo.

Para conjuntos de 300 tweets o más se considera que su depuración manual es muy extensa y debe ser automatizada. Para su automatización se implementa un clasificador de Bayes-Naive. El clasificador Bayer-Naive utilizado es una implementación de la librería Python Textblob \cite{textblobWebsite}.

Los tamaños de los distintos conjuntos dependiendo del tamaño del conjunto de tweets es el siguiente:

\begin{table}[h]
	\centering
	\begin{tabular}{| c | c | c |}
		\hline
		Nº tweets & Nº Entrenamiento & Nº Validación \\ \hline
		N $\leqslant$ 300	& Manual & Manual \\ \hline
		0 $\leqslant$ N $\leqslant$ 430	& N $*$ 0,2 & N*0,3	\\ \hline
		430 $\leqslant$ N & 200 & 100	\\ \hline
	\end{tabular}
	\caption {Cantidades conjuntos del clasificador utilizado}
\end{table}

Estas cantidades fueron determinadas de manera empírica en base a recomendaciones recogidas en foros y experimentos propios realizados con la librería de tal manera de obtener una precisión de clasificación siempre superior a 85\%.

\input{texs/pseudo-crear-clasificador.tex}	

La clasificación de los distintos tweets en las categorías \emph{pertenece al tópico} y \emph{no pertenece al tópico} se realiza mediante la función \emph{prob\_classify(tweet).max()} que retorna la etiqueta de la clasificación que posee mayor probabilidad según el clasificador para el tweet en específico \cite{naivebayesdoc}.

\input{texs/orden-geo.tex}

\input{texs/orden-rel.tex}	

\input{texs/get-urls.tex}

\subsubsection{ON/OFF Medios de prensa}
El botón \emph{ON/OFF Medios de prensa} permite ocultar o mostrar todos los tweets de la lista que hayan sido emitido por una cuenta registrada en el sistema como medio de prensa. Esta funcionalidad fue desarrollada con la intención de contar con la opción voluntaria de visualizar o no, los tweets de las cadenas de prensas, para privilegiar la lectura de tweets generados por personas o entidades sociales.
