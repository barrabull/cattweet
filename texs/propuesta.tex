\section{Arquitectura de la solución}
	\input{texs/arquitectura_plataforma.tex}
	
	\input{texs/diagrama_software.tex}
	
\section{Plataformas y herramientas utilizadas}

\input{texs/plataformas_herramientas.tex}

\section{Implementación del prototipo}
\input{texs/caracteristicas-computador.tex}

\input{texs/modelo-datos.tex}

\subsection{Análisis de la línea editorial del medio objetivo}
	\input{texs/analisis-linea-editorial.tex}
\newpage

\subsection{Geolocalización de usuarios}\label{sec:geo}
\label{subsec:geo1}
	\input{texs/implementacion-geo-usuarios.tex}

\newpage
\subsection{Captación de usuarios}

El proceso de captación del conjunto de usuarios esta diseñado con la intención de obtener todas y todos los usuarios residentes en territorio Chileno dado que dicho catastro no existe en ninguna fuente oficial actualizada. El procedimiento se basa en las siguientes dos consideraciones: c
\begin{enumerate}
	\item Los generadores de información poseen una gran base de seguidores \cite{JavaEtAl:07}.
	\item Es habitual que los seguidores de medios de prensa al querer difundir una información le escriban un tweet a algún medio de prensa o figura de autoridad, esperando que este realice un re-tweet, para llegar también a su base de seguidores.
\end{enumerate}

El proceso de construcción de la lista de usuarios se componen de dos grandes etapas, las cuales son explicadas a continuación:

\input{texs/etapas-captacion-usuarios.tex}

\subsubsection{Captura de los medios de prensa (MP)}

Para generar la lista de medios de prensa (MP) se accede a los medios de prensa registrados en las tres asociaciones más grandes de medios de comunicación de Chile:
\begin{itemize}
	\item \textit{ANP (Asociación Nacional de Prensa)} \cite{anpWebsite}: Asociación gremial constituida el 24 de agosto de 1951. Agrupa a los principales diarios y revistas del país.
	\item \textit{ANARCICH (Asociación nacional de Radios Comunitarias y Ciudadanas de Chile)} \cite{anarcichWebsite}: Es el organismo que agrupa a 300 radios comunitarias y ciudadanas de todo el país. 
	\item \textit{ARCHI (Asociación de Radiodifusores de Chile)} \cite{archiWebsite}: Fundada en 1933 es la organización gremial de medios de comunicación social más antigua de Chile.
\end{itemize}	

Ninguna de las asociaciones de medios de prensa considerados anteriormente (ANP, ANARCICH y ARCHI) cuentan con directorios públicos \cite{mediosArchi} \cite{mediosaAnp} \cite{mediosAnarcich} que provean las cuentas oficiales de twitter de los diversos medios. Por lo cual, para recolectar las cuentas de twitter de éstos, se implementó el siguiente algoritmo ejecutado por un ser humano:

\begin{algorithm}[H]
	\caption{Construcción lista de medios}\label{mediosPrensa}
	\begin{algorithmic}[1]
		\Function{getTwitterAccount}{listaMedios}
		\For{medio in listaMedios}
		\State busqueda $\gets$ 'site:twitter.com'+medio.nombre+medio.tipo +'chile'
		\State resultGoogle $\gets$ BusquedaGoogle ( busqueda, $limit=12$)
		\For{result in resultGoogle}
		\If{result.title \&\& result.description se relacionan con medio  }
		\State medio.screenName $\gets$ result.screenName
		\EndIf 
		\EndFor
		\EndFor
		\State return listaMedios
		\EndFunction	
		%	\Function{getUsersFromBd}{comuna}
		%		\State sql = 'SELECT usuario WHERE usuario.ubicacion LIKE "\%" + comuna;
		%		\State return execute(sql);
		%	\EndFunction	
	\end{algorithmic}
\end{algorithm}

Tras aplicar este algoritmo humano, los resultados obtenidos fueron los siguientes:

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		Asociación & Nº Miembros con cuentas & Nº miembros totales \\ \hline
		ANP & 43 & 0,00\% \\ \hline
		ANARCICH & 23 & 2,09\% \\ \hline
		ARCHI & XX & XX \\ \hline
	\end{tabular}
	\caption {Cantidad de miembros de las distintas asociaciones de prensa en Chile con cuentas en Twitter al 5 de junio del 2014.}
\end{table}


\subsubsection{Captura followers de los medios de prensa (FMP)}

Tras obtener la lista de medios de prensa, mediante la API de Twitter se recopilan los seguidores de cada uno de los medios de prensa. El algoritmo continuación realiza esta tarea requiere de realizar pero debe incluir intervalos de pausas para respetar las restricciones de número de solicitudes por hora que impone la API.

\begin{algorithm}[H]
	\caption{Captura de usuarios}\label{capturaUsuarios}
	\begin{algorithmic}[1]
		\Function{GetPop}{mediosPrensa}
		\For{medio in mediosPrensa} 
		\If{GetFriendsInformation(medio, api)}
		\State Sleep(2);
		\Else
		\State Sleep(60*15);
		\State GetFriendsInformation(medio, api)
		\EndIf
		\EndFor
		\EndFunction
		
		\Function{GetFriendsInformation}{user, api}	
		\State TwitterFriends $gets$ api.GetFollowers(screenName=user)
		\If {TwitterFriends.length > 0}
		\For {Friends in TwitterFriends}:
		\State SaveInBd(Friends)
		\EndFor
		\Else
		\State Sleep(60*15);
		\EndIf
		\EndFunction
		
	\end{algorithmic}
\end{algorithm}

Una de las dificultades presentadas en el algoritmo anterior, era que ante usuarios con más de 1,5 millones de seguidores la petición a la API se demoraba un tiempo excesivo (más de 48 horas) y retornaba error por \emph{timeout} de la conexión. Para sortear esta dificultad fue necesario modificar la API Python Twitter directamente, agregando el retorno del cursor aún cuando se agota la conexión con la API y guardando los resultados parciales de las respuestas. El cursor de una llamada en la API es similar a un índice que permite realizar solicitudes de manera segmentada a la API \footnote{ Al día 26/10/2015 no se encontraba disponible la mejora en el \emph{Github} oficial de la librería \cite{pythonTwitterGithub} }. Esta modificación fue realizada en base a las recomendaciones y comentarios disponibles en los grupos de desarrolladores de la librería \cite{pythonTwitterCode} \cite{pythonTwitterGithub}. 

\input{texs/alg-modificacion-api-twitter.tex}

El algoritmo se demora en promedio 2,6945531 segundos en descargar los datos de un usuario y almacenarlos en el sistema.

\subsection{Captura de tweets}

El proceso de captura de tweets se realiza obteniendo los 100 últimos tweets de cada uno de los usuarios y usuarias recolectadas en la fase anterior, sin discriminación ni priorización alguna, tal como muestra el siguiente algoritmo:

\begin{algorithm}[H]
	\caption{Algoritmo para la captura de tweets.}\label{getTweets}
	\begin{algorithmic}[1]
		\Function{GetTweets}{}
		\State usuarios $\gets$ getUsersFromBD();
		\For {usuario in usuarios}
		\State GetUserTimeline(id\_user=usuario.id);
		\EndFor
		\State time.sleep(5);
		\EndFunction
		
		\Function{GetUserTimeline}{id\_user}:
		\State statuses $\gets$ api.GetUserTimeline(user\_id=id\_user,count=100);
		\State SaveTweetInBD(statuses);
		
		\If {statuses.error == 34}
		\Comment{La cuenta ya no existe}
		\State return 1;
		\EndIf
		
		\If {statuses.error == 179}
		\Comment{La cuenta es privada}
		\State return 1;
		\EndIf
		
		\If {statuses.error == 88}
		\Comment{Limite de solicitudes excedidas}
		\State time.sleep(5*60);
		\State return
		\EndIf
		\EndFunction
	\end{algorithmic}
\end{algorithm}

El algoritmo planteado principalmente en su primera etapa realiza una búsqueda de los usuarios y sus respectivos estados referentes a si han sido recolectados sus últimos tweets (en cuyo caso se van a buscar los 100 tweets más recientes a partir del último recogido) o no (en cuyo caso se van a buscar los 100 tweets más recientes), posteriormente se almacenan en la base de datos los tweets recibidos. Es importante resaltar que este algoritmo gestiona las distintas pausas necesarias para respetar los límites de la API Twitter.

Si la cuenta no existe o es privada se elimina del conjunto de usuarios. El algoritmo se demora en promedio 0,9658139 segundos en descargar los tweets de un usuario y almacenarlos en el sistema.

\subsection{Procesamiento de los tweets}

El procesamiento de los tweets se define en tres procesos:
\begin{enumerate}
	\item{Definición del tópico.}
	\item{Obtención del conjunto de tweets relacionados al tópico.}
	\item{Depuración de conjunto de tweets relacionados al tópico.}
\end{enumerate}

\subsubsection{Definición del tópico}

Un tópico son las palabras claves que definen una búsqueda temática realizada por el administrador del sistema ingresado al sistema mediante la plataforma web, cada tópico posee los siguientes atributos:
\begin{itemize}
	\item Fecha de inicio : Se refiere a la fecha de inicio de emisión de los tweets objetivos que se requiere reunir.
	\item Fecha última actualización: Se refiere a la última fecha en la cual se realizó alguna modificación referente al tópico.
	\item Título: Se refiere a las palabras claves que definen al tópico. 
	\item Comuna: Comuna relacionada al tópico.
	\item Tasa de contenidos georeferenciados: Relación entre tweets con relación geográfica y los tweets totales.
	\item Cantidad de tweets relacionados: Total de tweets depurados del conjunto de tweets relacionados. 
\end{itemize}

\subsubsection{Obtención del conjunto de tweets relacionados al tópico}

Para obtener el conjunto de tweets relacionados al tópico se realiza una búsqueda en todos los tweets emitidos durante el periodo de interés
y que contenga las palabras claves que definen al tópico. Posteriormente se eliminan los tweets que tengan una similitud 0.85 tras realizar 
una comparación de sus textos utilizando la librería \emph{difflib}.

La consulta \emph{getTweetKeyword} se demora aproximadamente entre 30 y 130 segundos.

\begin{algorithm}[H]
	\caption{Obtención del conjunto de tweets relacionados al tópico}\label{getTweetsKeyword}
	\begin{algorithmic}[1]
		
		\Function{getTweetKeyword}{keywords,fecha}:
		%\Comment{Query tematica: va a buscar tweets que contengan una cierta keyword y retorna un array con las palabras que la contengan}
		\State tweets $\gets$ getTweetsFromBD(keywords, fecha);
		\State tweets $\gets$ eliminacionTweetsRepetidos(tweets);
		\State return tweets
		\EndFunction
	\end{algorithmic}
\end{algorithm}	



\subsubsection{Depuración de conjunto de tweets relacionados al tópico}

El proceso de depuración del conjunto de tweets obtenidos en el proceso anterior considera dos procesos distintos dependiendo del volumen de tweets involucrados.

Un gran problema en la depuración de los tweets es poder discernir si un tweet en particular se relaciona o no con la temática del tópico o si responde a una temática completamente distinta y fue relacionado con el tópico únicamente por concordancia textual. Por ejemplo, si buscamos tweets relacionados con la paralización del registro civil, con la keyword 'paro' nos gustaría filtrar todos los tweets que se refieran a un paro cardíaco o de la acción de levantarse.

Este problema fue abordado, considerando las siguientes premisas:
\begin{itemize}
	\item El administrador del sistema posee poco tiempo.
	\item Es fundamental filtrar con precisión los tweets que no corresponden a la temática.
\end{itemize}

Para conjuntos de tweets de menos de 300 tweets se considera que su depuración puede ser realizada de manera manual, debido a que no es un gran conjunto de datos.

Para conjuntos de tweets de 300 tweets o más se considera que su depuración manual es muy extensa y debe ser automatizada. Para su automatización se implementó un clasificador de Bayes-Naive. El valor para determinar el limite entre la utilización entre un método y otro se realizó en base a la regla de 80-20 para el conjunto de entrenamiento.

El clasificador Bayer-Naive utilizado es una implementación de la librería Python Textblob \cite{textblobWebsite}, librería para el procesamiento de lenguaje natural.

\input{texs/pseudo-crear-clasificador.tex}	

\input{texs/orden-geo.tex}

\input{texs/orden-rel.tex}	

\input{texs/get-urls.tex}

\subsubsection{ON/OFF Medios de prensa}
El botón \emph{ON/OFF Medios de prensa} permite ocultar o mostrar todos los tweets de la lista que hayan sido emitido por una cuenta registrada en el sistema como medio de prensa. Esta funcionalidad fue desarrollada con la intención de contar con la opción voluntaria de visualizar o no, los tweets de las cadenas de prensas, para privilegiar la lectura de tweets generados por personas o entidades sociales.
